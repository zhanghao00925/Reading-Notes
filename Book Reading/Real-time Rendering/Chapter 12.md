## Reprojection Techniques

重投影是基于重用前一帧中计算的样本的思想。正如它的名字所暗示的，这些样本被尽可能地从新的查看位置和方向重用。重投影方法的一个目标是将渲染成本分摊到多个帧上，即利用时间一致性。另一个目标是，如果应用程序未能及时完成当前帧的绘制，则形成一个近似的结果，在VR中比较重要。

重投影方法分为反向重投影和正向重投影。反向重投影[1264,1556]的基本思想如图所示。

【12.6】

对于之前被遮挡的区域，然后变得可见(例如图12.6中的深绿色区域)，没有阴影像素可用。这被称为缓存丢失。在这样的事件中，我们计算新的像素着色来填充这些洞。由于着色值的重用假定它们独立于任何类型的运动(对象、相机、光源)，所以明智的做法是不要在太多的帧上重用着色值。

反向重投影的另一种变体是存储速度缓冲区并在屏幕空间中执行所有测试，这避免了顶点的双重转换。

为了获得更好的质量，还可以使用run -average filter[1264,1556]，它会逐渐淘汰旧的值。对于空间抗锯齿，软阴影，和全局照明很有用。

前向重投影从帧t−1的像素开始，并将其投影到帧t中，因此不需要两double vertex shading次顶点着色。这些方法还需要处理成为可见的闭塞的地区,这是通常使用不同的启发式hole-filling方法完成,即从周围的像素推断出缺失区域的值。

总之forward reprojection的缺点在于重投影时的hole filling。

## Lens Flare and Bloom

透镜耀斑是一种光通过透镜系统或通过间接反射或其他意想不到的路径通过眼睛而引起的现象。有很多中现象，但最主要的是halo和ciliary corona。光晕是由晶状体的径向纤维结构引起的。它看起来像一个环围绕着光，它的外边缘带有红色，它的内部带有紫色。无论光源的距离有多远，光晕的表观大小都是恒定的。睫状冠来自于晶状体的密度波动，它以射线的形式出现，从一个点辐射出去，这个点可能会延伸到光环之外[1683]。

当镜头的某些部分在内部反射或折射光线时，相机镜头也会产生第二效果secondary effects。由于相机的光圈叶片的形状。条纹、辉光等。

在现实中，随着相机技术的进步，大多数这样的artifacts越来越少。然而，这些效果现在通常会以数字方式添加到真实的照片中。因为计算机显示器产生的光强度是有限制的，我们可以通过在图像中添加这样的效果来给人一种场景或物体亮度增加的印象[1951]。在照片、电影和交互式计算机图形中，由于它们的普遍使用，bloom效果和镜头光晕几乎是陈词滥调。尽管如此，如果运用得当，这样的效果可以给观众强烈的视觉暗示。

为了提供一个令人信服的效果，镜头光斑应该随着光源的位置而改变。King[899]创建了一组不同纹理的方块来代表镜头光斑。然后它们被定位在一条从屏幕上光源位置到屏幕中心的直线上。当光线远离屏幕中心时，这些方块会变得更小、更透明，随着光线向内移动，方块会变得更大、更不透明。

对于条纹，通过绘制半透明的billboard或对明亮的像素进行后处理，场景中明亮的物体或灯光的条纹也可以以表现出来。详细做法参考【参考文献】。

【fig 12.8】

bloom，即一个非常明亮的区域溢出到相邻的像素上，是通过结合几种现有的技术来实现的。主要的想法是创建一个bloom图像，它只包含需要“过度曝光”的明亮对象，使其变得模糊，然后将其重新合成到正常的图像中。使用的模糊通常是高斯分布[832]，尽管最近与参考镜头的匹配显示，该分布具有更多的尖峰形状[512]。制作此图像的一种常用方法是brightpass过滤器:保留所有亮像素，将所有暗像素变为黑色，通常在过渡点进行blend和scale[1616,1674]。

这个bloom图像可以在低分辨率下呈现，这样做可以节省时间并有助于提高过滤效果。这种降低分辨率的方法被用于许多后期处理效果。bloom图像可以向下采样几次并从生成的图像集中重新采样，从而产生更宽的模糊效果，同时最小化采样成本[832,1391,1918]。

不同于阈值化，高动态范围的图像可以被过滤以获得更好的结果[512,832]。低动态范围和高动态范围的水华可以分别计算和合成，以更令人信服的方式捕获不同的现象[539]。其他的变体是可能的，例如，前一帧的结果也可以添加到当前帧，给动画对象一个条纹发光[815]。

【Fig 12.9】

## Depth of Field

对于一个给定设置的相机镜头，有一个范围内的物体是在焦距内的，即它的景深。在这个范围之外的物体是模糊的——越远，就越模糊。在摄影中，这种模糊与光圈大小和焦距有关。孔径的减小增加了景深，即，更大范围的深度聚焦，但减少了形成图像的光量(章节9.2)。在户外白天拍摄的照片通常有很大的景深，因为光量足以允许一个小的光圈，理想的光圈是针孔相机。在光线昏暗的房间里，景深会明显变窄。因此，控制景深效果的一种方法是将它与色调映射联系起来，使失焦的物体随着光线的减弱而变得更加模糊。

[fig 12.10]

可以使用累加缓冲器来模拟景深[637]。参见图12.11。通过改变镜头上的视角位置并保持焦点固定，物体相对于焦点的距离会变得更加模糊。但是，与其他累积效果一样，这种方法需要在每张图像上花费大量的渲染时间。

[fig 12.11]

为了提高效率，许多方法可以使用较低级别的细节来处理焦点不清晰的对象。

可以分为三个区域:焦点附近的区域(焦点场或中场)，焦点以外的区域(远场)和焦点附近的区域(近场)。对于焦距处的表面，每个像素都显示出一个焦点清晰的区域，因为所有累积的图像都有大致相同的结果。焦点场是一个深度范围，在这个深度范围内，对象只是稍微失焦，例如，少于半个像素[209,1178]。这个范围就是摄影师所说的景深。

这个问题的一个解决方案是创建单独的图像层。渲染焦点对象的一个图像，远处的一个对象，以及近处的一个对象。这可以通过改变近/远剪切平面位置来实现。近场和远场的图像被模糊，然后这三个图像按前后顺序组合在一起[1294]。这种2.5维方法之所以被称为2.5维方法，是因为二维图像是给定深度和组合的，在某些情况下提供了合理的结果。当物体跨越多个图像时，这种方法就会失效，从模糊突然变成聚焦。此外，所有经过过滤的物体都有一致的模糊度，没有任何距离变化[343]。

另一种方法是考虑景深如何影响表面上的单一位置。想象一个表面上的小点。当表面聚焦时，点通过单个像素可见。如果表面没有对焦，点会出现在附近的像素点上，这取决于不同的视图。在极限处，点将在像素网格上定义一个填充的圆。这就是circle of confusion。

在摄影中，焦点之外的区域的美学品质被称为“模糊”(bokeh)，来自日语。穿过光圈的光线通常分布均匀，而不是某种高斯分布[1681]。circle of confusion的形状与孔径叶片的数量和形状以及大小有关。一个便宜的相机将产生模糊的五边形而不是完美的圆形。

计算景深效果的一种方法是获取每个像素在一个表面上的位置，并将其着色分散到这个圆或多边形内的相邻像素上。分散的概念不能很好地映射到像素着色器的功能上。

一种解决方案是为每一个近场和远场像素渲染一个精灵sprite(章节13.5)[1228,1677,1915]。每个精灵被渲染到一个单独的层，精灵的大小由circle of confusion的半径决定。每一层存储所有重叠精灵的平均混合和，然后将每一层合成到下一层。这种方法有时被称为前向映射forward mapping技术[343]。即使使用图像下采样，这种方法也可能很慢，而且更糟的是，需要一定的时间，特别是当聚焦场很浅的时候[1517,1681]。

另一种方法是假设一个像素周围的局部邻域具有相同的深度。有了这个想法，就可以进行收集操作。因此，一种实现景深效果的方法是根据每个像素的深度对其表面进行模糊[1672]。深度定义了一个circle of confusion，即采样区域的宽度。这种收集方法称为反向映射或反向映射方法backward mapping or reverse mapping。

大多数实用的算法都是从一个视角开始的初始图像。这意味着，从一开始，一些信息就被遗漏了。场景的其他视图将看到在这个单一视图中不可见的部分表面。正如Pesce所指出的，我们应该尽量利用现有的可视样本[1390]。

作者介绍了Bukowski等人[209,1178]提出的方法及其遇到的问题的解决方案。他们的方案为每个像素生成一个符号值，表示基于深度的circle of confusion的半径。这个半径可以从相机设置和特性中得到，但是艺术家通常喜欢控制效果，所以可以选择指定近景、焦距和远景的范围。半径符号指定像素是在近场还是远场，其中- 0.5 < r < 0.5是焦点场，在焦点中考虑半像素模糊。

这个值被用来将图像分离成两个图像，分别是近场图像和其余图像，每个图像都用一个可分离的滤波器进行下采样和模糊处理。这种分离是为了解决一个关键问题，即近场中的物体边缘应该是模糊的。如果我们根据每个像素的半径对其进行模糊处理，并将其输出到一个单独的图像中，那么前景对象可能是模糊的，但具有锐利的边缘。

【fig 12.13】

我们想要的是让近场中的物体平滑地模糊，并产生超出其边界的效果。这是通过在一个单独的图像中写入和模糊近场像素来实现的。此外，这个近场图像的每个像素都被赋予一个alpha值，表示它的混合因子，这也是模糊的。对于远场模糊，丢弃比采样像素远得多的邻近对象。

在基于circle of confusion进行分离和模糊处理后，进行合成。circle of confusion是用来在在焦点图像和远场图像之间线性插值。这个半径越大，使用的远场结果就越模糊。然后使用近场图像的alpha覆盖值将近场图像混合到这个插值结果上。通过这种方式，近场的模糊内容在背景上得到了很好的传播。

粒子可能以其他方式处理得更好，因为透明可能会导致问题。尽管如此，由于唯一的输入是一个颜色和深度缓冲区，并且只使用三个后处理pass，所以这种方法是简单且相对健壮的。

接下来介绍一些其他新方法。

第一种方法使用了一种方法，我们将在下一节中再次介绍:动态模糊。想象把图像中的每个像素转换成相应的circle of confusion，它的强度与圆圈的面积成反比。给定一个像素，我们要确定所有重叠位置的circle of confusion，并按排序将它们混合在一起。

【fig 12.15】

但是对找到的片段进行排序在GPU上非常昂贵。因此使用了一种称为“scatter as you gather”的方法。选择z深度最低的重叠邻域(最近距离)表示较近的图像。任何其他在z深度上与它相当接近的重叠邻居都利用alpha blend混合，取平均值，颜色和alpha都存储在“前景”层中。其他重叠的邻域以类似的方式进行求和和求平均值，并将结果放在单独的“背景”层中。细节请参考【文献】。

在一些较老的电子游戏中使用的另一种方法是基于计算热量扩散的概念。图像被认为是一个向外扩散的热分布，每个circle of confusion代表该像素的热导率。焦点区域是一个完美的绝缘体，没有扩散。

更多内容请参考【文献】。

## Motion Blur

为了绘制可信的时序图片，高帧率以及稳定的帧率是非常重要的。流畅和连续的运动是令人满意的，太低的；帧率会造成运动颠簸。电影以24FPS播放，但是湖南的环境是的人眼对闪烁更加不敏感。更重要的是，电影的帧是天然motion blur的图片，但是实时绘制的不是。

快速移动的物体看起来很不稳定，没有运动模糊，在帧之间“跳跃”了很多像素。这可以被认为是一种走样，但是是在时域上的，motion blur可以被认为是一种时域上的反走样。正如提高显示分辨率可以减少锯齿但不能消除锯齿一样，提高帧速率也不能消除运动模糊。视频游戏的特点是镜头和物体的快速运动，因此运动模糊可以显著改善游戏的视觉效果。30帧的动态模糊效果通常比60帧的效果更好。

运动模糊取决于相对运动。如果一个物体在屏幕上从左到右移动，它在屏幕上就会水平模糊。如果相机跟踪一个移动的物体，物体不会模糊——背景会模糊。

与景深类似，积累一系列图像提供了一种创建动态模糊的方法。当快门打开时，一帧有持续时间。场景在这个时间段的不同时间被渲染，相机和对象被重新定位。合成的图像被混合在一起，形成了一个模糊的图像，其中物体相对于相机的视角在移动。对于实时渲染，这样的过程通常会产生反效果，因为它可以大大降低帧速率。此外，如果对象移动得很快，artifacts就会可见。随机栅格化可以避免多幅图像混合时出现的重影现象，而是产生一些噪声。

如果想要的是运动的暗示，积累的概念可以用一种巧妙的方式。假设一个运动中的模型的八帧被生成并加到一个高精度的缓冲区中，然后取平均值并显示出来。在第9帧，再次渲染和积累模型，但也在这个时候，第1帧的渲染再次执行，并从求和结果中减去。缓冲区现在有8帧的模糊模型，帧2到9。在下一帧，我们减去第二帧，再加上第十帧，同样得到八帧的和，从第三帧到第十帧。这给了一个高度模糊的艺术效果，代价是每帧渲染场景两次。

有几个不同的运动模糊的来源，每个都有方法可以应用于它。这些变化可以分为摄像机方向变化、摄像机位置变化、对象位置变化和对象方向变化，其复杂程度大致依次递增。如果相机保持它的位置，整个世界可以被认为是一个围绕着观众的天空盒子。仅仅是方向的改变就会造成模糊，模糊的方向指向整个图像。给定方向和速度，我们沿着这个方向对每个像素进行采样，速度决定了滤波器的宽度。这种方向性模糊被称为线积分卷积(LIC)。

如果相机的位置发生了变化，视差就会发挥作用，比如，远处的物体移动的速度变慢了，所以模糊也就少了。当相机向前移动时，视差可能会被忽略。径向模糊可能是巨大的，来产生戏剧夸大效果。

【fig 12.18】

Rosado[1509]描述了使用前一帧的相机视图矩阵来计算飞行中的速度。其思想是将像素的屏幕位置和深度转换回世界空间位置，然后使用前一帧的摄像机将这个世界点转换为屏幕位置。这些屏幕空间位置之间的差就是速度矢量velocity vector，它用于模糊该像素的图像。组合的结果可以以四分之一屏幕的大小绘制，既节省像素处理，又滤除了噪声[1428]。

如果物体彼此独立运动，情况就更复杂了。一个直接的，但用处有限的方法是渲染模糊本身。这就是绘制线段来表示运动粒子的基本原理。这个概念可以扩展到其他对象。想象一把剑在空中划过。在刀锋前后，沿刀锋边缘分别添加两个多边形。这些可以动态地建模或生成。这些多边形使用每个顶点的alpha透明度，因此当一个多边形遇到剑的时候，它是完全不透明的，而在多边形的外缘，alpha是完全透明的。这个想法是，模型在运动方向上具有透明度，模拟剑在(假想的)快门打开的部分时间内覆盖这些像素的效果。

这种方法可以用于简单的模型，例如摆动的剑刃，但是纹理、高光和其他特征也应该是模糊的。每个运动的表面都可以被看作是单独的样本。早期的运动模糊方法分散这些样本，通过在运动方向上扩展几何形状。这种几何操作非常昂贵，因此已经开发出了“收集即分散”的方法。对于景深，我们将每个样本扩展到其circle of confusion的半径。对于移动样本，我们将每个样本沿着其在帧中移动的路径拉伸，类似于LIC。快速移动的样本覆盖的面积更大，因此在每个位置上的影响更小。从理论上讲，我们可以在一个场景中提取所有的样本，并将它们画成半透明的线段，按顺序排列。

[fig 12.19]

随着更多的样本被采集，产生的模糊在它的前缘和后缘有一个平滑的透明渐变。

因此需要知道每个像素表面的速度。一个被广泛采用的方法是使用velocity buffer。为了创建这个缓冲区，在模型的每个顶点插入屏幕-空间速度。速度可以通过应用于模型的两个建模矩阵来计算，一个用于前一帧，另一个用于当前帧。顶点着色程序计算位置的差异，并将此向量转换为相对屏幕空间坐标。

【FIG 12.20】

一旦速度缓冲区形成，每个物体在每个像素的速度是已知的。未模糊的图像也被渲染。但是要注意，我们遇到了一个类似之前DOF时的问题，单一的图像不能获得所有数据。对于交互式动态模糊，我们从一个定时序列中取出一个帧，并将其用作代表性图像。我们尽可能地使用这些数据，但所需的所有数据并不总是存在，这可能会造成artifacts。

有了这个帧和速度缓冲器，我们就可以重建物体对每个像素的影响，使用一个“收集即分散”的运动模糊系统。一种方法是:在第一个pass中，为屏幕的每个部分计算最大速度，例如，每个8×8像素块(第23.1节)，存入一个buffer中。第二个pass中，对生成的buffer的3*3区域找到最大值（TBD）。

最后对运动模糊图像进行了计算。与景深类似，对每个像素的邻域进行检测，以确定可能快速移动并重叠像素的样本。不同的是，每个样本都有自己的速度，沿着自己的路径。已经有了一些不同的方法来过滤和混合相关的样本。一种方法是利用最大速度的大小来确定核的方向和宽度。如果该速度小于半像素，则不需要运动模糊[1173]。否则，图像将沿最大速度方向进行采样。注意遮挡在这里很重要，因为它与景深有关。一个在静态对象后面快速移动的模型不应该让它的模糊效果溢出到这个对象之上。如果发现相邻样本的距离足够接近像素的z深度，则认为它是可见的。这些样本混合在一起形成了前景的贡献。

有几种采样和滤波的方法用于改进这种方法的观感。为了避免重影，样本位置随机抖动半个像素[1173]。更多参见【参考文献】。


在电子游戏中，玩家的体验通常不像看电影，而是在他们的直接控制下，以一种不可预知的方式改变视图。在这些情况下，运动模糊有时可能应用不好，导致分散注意力或眩晕。眼动跟踪设备和更高的帧率可能有助于改善运动模糊或完全消除它的应用。
